{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Training data placeholder\n",
    "\n",
    "Define a [placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) tensor for the training data that you will load. Call the placeholder `X`. You should use the 'type' `float32` for the values that will be held in the tensor. You also need to specify the 'shape' of your tensor:\n",
    " * The first dimension will be the batch size - set it to `None` to start with.\n",
    " * The second and third dimensions will be the width and height of your training images.\n",
    " * The fourth dimension will be the number of values per pixel in the image. The images in the training set are grayscale.\n",
    " You can optionally provide a name for the placeholder tensor if you like.\n",
    " \n",
    " Note: Even though the values for the pixels in the training data are integers you will later perform a matrix multiplication against a matrix of floats, so specify a type of `float32`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1], 'training-data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Variables for weights and biases\n",
    "\n",
    "When you train your model Tensorflow will compute the best weights and biases it can to get accurate classifications. Define [variables](https://www.tensorflow.org/api_docs/python/tf/Variable) to the hold the state of the weights and biases.\n",
    "\n",
    " * Call your weight variable `W` and your bias variable `b`. \n",
    " * The weights and biases needed to get the most accurate classification for an image will not be known until you train your model. Start by creating a tensor will all elements set to zero (see [tf.zeros(shape, dtype=tf.float32)](https://www.tensorflow.org/api_docs/python/tf/zeros))\n",
    " * The dimensions `W` will be the size of your image vector (flattened from a 28x28 matrix) and the number of possible weights chosen (use 10).\n",
    " * Also specify 10 possible biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create two variables\n",
    "#  * W (a matrix) to hold the weights.\n",
    "#  * b (a vector) to hold the biases.\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# Initialise the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Define the model\n",
    "\n",
    "Now you are going to define the TensorFlow model:\n",
    "\n",
    "$ Y = softmax(X.W + b) $\n",
    "\n",
    "\n",
    "You should use softmax as our activation function. The softmax function will be applied to each flattened image (line by line in batches) and take the matrix multiplication of our training image and the computed weights matrix plus a bias (from 10 possible values) as an argument.\n",
    "\n",
    "Now you should define the above model in TensorFlow code.\n",
    " * Call the variable to hold the predictions `Y`.\n",
    " * [tf.nn.softmax](https://www.tensorflow.org/versions/master/api_docs/python/tf/nn/softmax)\n",
    " * [tf.matmul](https://www.tensorflow.org/api_docs/python/tf/matmul)\n",
    " * Remember that the training images are 28 x 28 and need to be reshaped into a single row of pixels. Use the [reshape](https://www.tensorflow.org/api_docs/python/tf/reshape) function to flatten `X`.\n",
    "\n",
    "Define a placeholder tensor called Y_ to hold the correct answers. It will be a matrix of _1-hot_ encoded vectors for the batch (one position for the correct answer is encoded to 1 and all the others are encoded as 0).\n",
    " * Use tf.float32 as the type of the vector.\n",
    " * Use `None` to represent the batch size. TensorFlow has a delayed execution model and the batch size will be determined when you run the training.c \n",
    " * The number of values for each answer is 10.\n",
    " \n",
    "#### Tasks:\n",
    " * Flatten the image matrix\n",
    " * Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-af2d76b5b84d>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-af2d76b5b84d>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    XX = #TODO\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Flatten the training images into a single row of pixels.\n",
    "XX = #TODO\n",
    "\n",
    "# Define the model\n",
    "Y = #TODO\n",
    "\n",
    "# Placeholder for correct answers\n",
    "Y_ = tf.placeholder(tf.float32, [None, 10], 'correct-answers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Define the error function\n",
    "\n",
    "When you train your model a loss function will be applied and the 'optimizer' that you will define will minimize the value of this function as it trains the model. The following function, known as 'Cross Entropy', is proven to work well:\n",
    "\n",
    "\\begin{equation*}\n",
    "cross\\ entropy : - \\sum_{i} Y_{i}' \\log (Y_i)\n",
    "\\end{equation*}\n",
    "\n",
    " \n",
    "#### Tasks:\n",
    " * Define the error function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define the error function (use cross entropy)\n",
    "cross_entropy = #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Keep track of the prediction accuracy\n",
    "\n",
    "Define functions to check if the predicted result is correct and to check the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "is_correct = tf.equal(tf.argmax(Y, 1), tf.argmax(Y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Configure the optimizer\n",
    "\n",
    "This is where TensorFlow will do the hard work for you. Write code to configure TensorFlow to use the [gradient descent](https://en.wikipedia.org/wiki/Gradient_descent) algorithm when training your model. TensorFlow will iterate down the gradient and make appropriate adjustments to the weights in order to increase the accuracy. See [GradientDescentOptimizer](https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer).\n",
    "\n",
    " \n",
    "#### Tasks:\n",
    " * Define the optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# configure a GradientDescentOptimizer. A learning rate of `0.005` works well.\n",
    "optimizer = #TODO\n",
    "\n",
    "train_step = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Load the training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\n",
    "\n",
    "# Download images and labels into mnist.test (10K images+labels) and mnist.train (60K images+labels)\n",
    "mnist = read_data_sets(\"data\", one_hot=True, reshape=False, validation_size=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train your model!\n",
    "\n",
    "We will run 1000 iterations of training in batches of 100 images and calculate the accuracy every 100 iterations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(1000):\n",
    "    # Load a batch of 100 images and the correct answers for them\n",
    "    batch_X, batch_Y = mnist.train.next_batch(100)\n",
    "    \n",
    "    train_data = {X: batch_X, Y_: batch_Y}\n",
    "\n",
    "    # Run the training step (back propagation)\n",
    "    sess.run(train_step, feed_dict=train_data)\n",
    "    \n",
    "    # Check the accuracy every 100 iterations of our training run\n",
    "    if i % 100 == 0:\n",
    "        # Accuracy against the *training* data\n",
    "        #print(sess.run(accuracy, feed_dict=train_data))\n",
    "        train_acc, train_ent = sess.run([accuracy, cross_entropy], feed_dict=train_data)\n",
    "        \n",
    "        test_data = {X: mnist.test.images, Y_: mnist.test.labels}\n",
    "        test_acc, test_ent = sess.run([accuracy, cross_entropy], feed_dict=test_data)\n",
    "        \n",
    "        print(\"[TRAIN - acc:%1.2f ent: %10.4f]     [TEST -  - acc:%1.2f ent: %10.4f]\" \n",
    "              % (train_acc, train_ent, test_acc, test_ent))\n",
    "        \n",
    "print('---------- FINAL ACCURACY ----------')\n",
    "print(sess.run(accuracy, feed_dict=test_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
